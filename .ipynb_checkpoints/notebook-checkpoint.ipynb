{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from moduleLoading import LoadingMethods\n",
    "from modulePreProcessing import ScalingMethods, FeatureMethods, boxplot_features\n",
    "from moduleModelTraining import TrainingMethods\n",
    "from moduleMetrics import MetricsMethods\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from collections import Counter\n",
    "from joblib import dump\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Jupyter QtConsole\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-9ca66c7bcfe3>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-9ca66c7bcfe3>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    ``fm = FeatureMethods()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# class instances\n",
    "load = LoadingMethods()\n",
    "scale = ScalingMethods()\n",
    "fm = FeatureMethods()\n",
    "train = TrainingMethods()\n",
    "evaluate = MetricsMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final features\n",
    "ff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db and fetch data\n",
    "df = load.connect_and_fetch(\"127.0.0.1\", \"mci_db\", \"root\", \"toor\", \"SELECT * FROM v7\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target class (14 available, 6 moca, 6 mmse, 2 diffs)\n",
    "target_class = \"moca_pre_binary_binned\"\n",
    "df = load.separate_target_class(df, target_class)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize !!! also totals and avgs? check!\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='quantile')\n",
    "dfPartToDiscretize = df['age']\n",
    "df['age'] = discretizer.fit_transform(df[['age']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of categorical to numerical. \n",
    "# no need for that particular encoding,\n",
    "# since we fetch their ids from the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove low variance features\n",
    "df = fm.remove_low_variance_features(df, (.8 * (1 - .8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle outliers\n",
    "df = scale.handle_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "columnsToIgnore = ['gsId', 'gsStartTime', 'target_class']\n",
    "df = scale.use_min_max(df, columnsToIgnore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance inspection using a classifier\n",
    "# MDI feature importance and feature values permutation importance\n",
    "\n",
    "# user related independent variables\n",
    "features_to_inspect = ['age', 'education','laptop_usage', 'smartphone_usage', \n",
    "                       'family_med_history', 'exercising', 'marital_status_1', \n",
    "                       'marital_status_3', 'hypertension']\n",
    "fm.inspection_using_classifier(df, features_to_inspect)\n",
    "\n",
    "# session data related independent variables\n",
    "features_to_inspect = ['total_gr_in_gs', 'total_success_rounds_in_session', \n",
    "                       'total_win_gr_points_in_gs', 'avg_gr_time_in_gs', \n",
    "                       'avg_gr_time_win_gr_in_gs']\n",
    "\n",
    "fm.inspection_using_classifier(df, features_to_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature correlation inspection\n",
    "\n",
    "# example\n",
    "# https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#handling-multicollinear-features\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "X = df[['age', 'education','laptop_usage', 'smartphone_usage', \n",
    "        'family_med_history', 'exercising', 'marital_status_1', \n",
    "        'marital_status_3', 'hypertension', \n",
    "        'total_gr_in_gs', 'total_success_rounds_in_session', \n",
    "        'total_win_gr_points_in_gs', 'avg_gr_time_in_gs', \n",
    "        'avg_gr_time_win_gr_in_gs']]\n",
    "corr = spearmanr(X).correlation\n",
    "corr_linkage = hierarchy.ward(corr)\n",
    "feature_names = X.columns.tolist()\n",
    "dendro = hierarchy.dendrogram(corr_linkage, labels=feature_names, ax=ax1, leaf_rotation=0, orientation='right')\n",
    "dendro_idx = np.arange(0, len(dendro['ivl']))\n",
    "\n",
    "ax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro['ivl'], rotation='vertical')\n",
    "ax2.set_yticklabels(dendro['ivl'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.jupyter.org/github/justmarkham/scikit-learn-tips/blob/master/notebooks/23_linear_model_coefficients.ipynb\n",
    "#https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.clf()\n",
    "# X_indices = np.arange(X.shape[-1])\n",
    "# selector = SelectKBest(f_classif, k=4)\n",
    "# selector.fit(X_train, y_train)\n",
    "# scores = -np.log10(selector.pvalues_)\n",
    "# scores /= scores.max()\n",
    "# plt.bar(X_indices - .45, scores, width=.2,\n",
    "#         label=r'Univariate score ($-Log(p_{value})$)')\n",
    "# plt.title(\"Comparing feature selection\")\n",
    "# plt.xlabel('Feature number')\n",
    "# plt.yticks(())\n",
    "# plt.axis('tight')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection for user demographics, medical profile, technology familiarity related features\n",
    "\n",
    "# independent variables\n",
    "X = df[['age', 'education','laptop_usage', 'smartphone_usage', \n",
    "         'family_med_history', 'exercising', 'marital_status_1', \n",
    "         'marital_status_3', 'hypertension']]\n",
    "\n",
    "# target class\n",
    "targetClassIndex = df.columns.get_loc('target_class')\n",
    "y = df.iloc[:, targetClassIndex]\n",
    "\n",
    "# feature selection\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "Xresults = selector.fit_transform(X.values, y.values)\n",
    "# selector = check for coeff in selector ???\n",
    "\n",
    "# print(Xresults.shape)\n",
    "# print(type(Xresults))\n",
    "#get selected as: array([3, 4], dtype=int64)\n",
    "selectedFeaturesIndices = selector.get_support(indices=True)\n",
    "# print('selectedFeaturesIndices ', selectedFeaturesIndices)\n",
    "\n",
    "#get selected as: Index(['age', 'education'], dtype='object')\n",
    "selectedFeaturesIndicesNames = X.columns[selectedFeaturesIndices.tolist()]\n",
    "# print('selectedFeaturesIndicesNames ', selectedFeaturesIndicesNames)\n",
    "\n",
    "#get selected as list: ['age', 'education']\n",
    "selectedFeatures = X.columns[selectedFeaturesIndices.tolist()].values.tolist()\n",
    "print(selectedFeatures)\n",
    "ff += selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection for MCI Rehab recorded game performance related features\n",
    "\n",
    "# independent variables\n",
    "X = df[['total_gr_in_gs', 'total_success_rounds_in_session', \n",
    "        'total_win_gr_points_in_gs', 'avg_gr_time_in_gs', \n",
    "        'avg_gr_time_win_gr_in_gs']]\n",
    "\n",
    "# target class\n",
    "targetClassIndex = df.columns.get_loc('target_class')\n",
    "y = df.iloc[:, targetClassIndex]\n",
    "\n",
    "# feature selection\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "Xresults = selector.fit_transform(X.values, y.values)\n",
    "# print(Xresults.shape)\n",
    "# print(type(Xresults))\n",
    "#get selected as: array([3, 4], dtype=int64)\n",
    "selectedFeaturesIndices = selector.get_support(indices=True)\n",
    "# print('selectedFeaturesIndices ', selectedFeaturesIndices)\n",
    "\n",
    "#get selected as: Index(['age', 'education'], dtype='object')\n",
    "selectedFeaturesIndicesNames = X.columns[selectedFeaturesIndices.tolist()]\n",
    "# print('selectedFeaturesIndicesNames ', selectedFeaturesIndicesNames)\n",
    "\n",
    "#get selected as list: ['age', 'education']\n",
    "selectedFeatures = X.columns[selectedFeaturesIndices.tolist()].values.tolist()\n",
    "print(selectedFeatures)\n",
    "ff += selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train models\n",
    "\n",
    "# Either shuffle=True, random_state=7 Or stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[ff], y, test_size=0.3, shuffle=False)\n",
    "\n",
    "clfs = {\n",
    "    'lr': LogisticRegression(random_state=7),\n",
    "    'dt' : DecisionTreeClassifier(max_depth=4),\n",
    "    'rf' : RandomForestClassifier(max_depth=4, random_state=7)\n",
    "}\n",
    "custom_ensemble = VotingClassifier([('clf1', clfs.get('lr')), \n",
    "                                    ('clf2', clfs.get('dt')), \n",
    "                                    ('clf3', clfs.get('rf'))], voting='soft')\n",
    "clfs['ce'] = custom_ensemble\n",
    "\n",
    "trained_models = train.train_models(clfs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models\n",
    "evaluate.generate_metrics(trained_models, X_test, y_test, ['accuracy', 'precision', 'recall', 'f1'], show_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
