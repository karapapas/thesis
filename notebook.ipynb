{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from moduleDatabase import DatabaseMethods\n",
    "from moduleUtilities import UtilityMethods\n",
    "from modulePreProcessing import TransformationMethods, FeatureMethods\n",
    "from moduleModelTraining import TrainingMethods\n",
    "from moduleMetrics import MetricsMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class instances\n",
    "db = DatabaseMethods()\n",
    "ut = UtilityMethods()\n",
    "tf = TransformationMethods()\n",
    "fm = FeatureMethods()\n",
    "train = TrainingMethods()\n",
    "evaluate = MetricsMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db and fetch data\n",
    "df = db.fetch(\"SELECT * FROM v7\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the distribution of potential target classes\n",
    "ut.inspect_target_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target class (14 available, 6 moca, 6 mmse, 2 diffs)\n",
    "df = db.separate_target_class(df, \"moca_pre_binary_binned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling outliers. ignoring outliers for user data.\n",
    "# The whole process should avoid outliers in the first place.\n",
    "df = tf.handle_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of categorical to numerical. \n",
    "# No need for that particular encoding, since we fetch their ids from the view, unless we implement the Service, \n",
    "# then every transformation should be done in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Discretize 1) to calculate variance in same scale 2) because I need to convert any feature of float type to int early.\n",
    "columns_to_discretize = ['age','avg_gr_time_win_gr_in_gs', 'avg_gr_time_win_gr_in_gs', 'avg_gr_time_in_gs', \n",
    "                         'total_win_gr_points_in_gs', 'total_gr_in_gs', 'total_success_rounds_in_session']\n",
    "fm.discretize_features(df, columns_to_discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# remove low variance features. VarX = p(1-p). Where p is the probability of a value of a feature.\n",
    "df = fm.remove_low_variance_features(df, (.8 * (1 - .8)), ddof_val=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "# TODO try to use StandardScaler for user data.\n",
    "columnsToIgnore = ['userId', 'gsId', 'gsStartTime', 'target_class']\n",
    "df = tf.use_min_max(df, columnsToIgnore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature correlation inspection. Select features correlated to target class not between them.\n",
    "fs = ['age', 'education','laptop_usage', 'smartphone_usage', 'family_med_history', 'exercising', 'marital_status_1',\n",
    "      'marital_status_3', 'hypertension', 'total_gr_in_gs', 'total_success_rounds_in_session', 'total_win_gr_points_in_gs', \n",
    "      'avg_gr_time_in_gs', 'avg_gr_time_win_gr_in_gs', 'target_class']\n",
    "fm.correlation_inspection(df, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['age', 'education','laptop_usage', 'smartphone_usage', 'family_med_history', 'exercising',\n",
    "                'marital_status_1', 'marital_status_3', 'hypertension', \n",
    "                'total_gr_in_gs', 'total_success_rounds_in_session', 'total_win_gr_points_in_gs', \n",
    "                'avg_gr_time_in_gs', 'avg_gr_time_win_gr_in_gs']\n",
    "cl1_features = ['laptop_usage', 'age', 'avg_gr_time_win_gr_in_gs', 'education', 'avg_gr_time_in_gs']\n",
    "cl2_features = ['marital_status_3', 'family_med_history']\n",
    "cl3_features = ['exercising', 'smartphone_usage', 'total_win_gr_points_in_gs', 'total_success_rounds_in_session',\n",
    "                'total_gr_in_gs', 'marital_status_1', 'hypertension']\n",
    "session_features = ['total_gr_in_gs', 'total_success_rounds_in_session', 'total_win_gr_points_in_gs', \n",
    "                    'avg_gr_time_in_gs', 'avg_gr_time_win_gr_in_gs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance inspection using a classifier\n",
    "# MDI feature importance and feature values permutation importance\n",
    "\n",
    "fm.inspection_using_classifier(df, all_features)\n",
    "fm.inspection_using_classifier(df, cl1_features)\n",
    "fm.inspection_using_classifier(df, cl2_features)\n",
    "fm.inspection_using_classifier(df, cl3_features)\n",
    "fm.inspection_using_classifier(df, session_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance inspection using Univariate Feature Selection\n",
    "# More specifically, ANOVA and some traditional Regressors\n",
    "# TODO check also for the target as continuous  \n",
    "\n",
    "fm.inspection_using_regressors(df, all_features)\n",
    "fm.inspection_using_regressors(df, cl1_features)\n",
    "fm.inspection_using_regressors(df, cl2_features)\n",
    "fm.inspection_using_regressors(df, cl3_features)\n",
    "fm.inspection_using_regressors(df, session_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "cross_val_num=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe samples for the training and evaluation process\n",
    "selected_features = ['education', 'avg_gr_time_in_gs',\n",
    "                     'family_med_history',\n",
    "                     'total_gr_in_gs']\n",
    "x = df[selected_features]\n",
    "y = df.iloc[:, df.columns.get_loc('target_class')]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=7, test_size=test_size)\n",
    "print('x:',x.shape,' y:',y.shape)\n",
    "print('x_train:',x_train.shape,' x_test:',x_test.shape,' y_train:',y_train.shape,'y_test:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"Before SMOTE OverSampling. NC: {}\".format(sum(y_train==2)))\n",
    "print(\"Before SMOTE OverSampling. AD-MCI: {} \\n\".format(sum(y_train==1)))\n",
    "\n",
    "smote_tf = SMOTE(random_state=2)\n",
    "smote_x, smote_y = smote_tf.fit_sample(x_train, y_train.ravel())\n",
    "smote_train_x, smote_test_x, smote_train_y, smote_test_y = train_test_split(smote_x, smote_y, random_state=7, test_size=test_size)\n",
    "\n",
    "print('smote_x:',smote_x.shape,' smote_y:',smote_y.shape)\n",
    "print('smote_train_x:',smote_train_x.shape,' smote_test_x:',smote_test_x.shape,' smote_train_y:',smote_train_y.shape,' smote_test_y:',smote_test_y.shape, '\\n')\n",
    "\n",
    "print(\"Before SMOTE OverSampling. NC: {}\".format(sum(smote_y==2)))\n",
    "print(\"Before SMOTE OverSampling. AD-MCI: {} \\n\".format(sum(smote_y==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train models before oversampling\n",
    "trained_models = train.train_models(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models before oversampling\n",
    "evaluate.generate_metrics(trained_models, x_test, y_test, ['accuracy', 'precision', 'recall', 'f1'], \n",
    "                          cv_num=cross_val_num, show_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models after oversampling\n",
    "trained_models_smote = train.train_models(smote_train_x, smote_train_y, smote_test_x, smote_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate models after sampling\n",
    "evaluate.generate_metrics(trained_models_smote, smote_test_x, smote_test_y, ['accuracy', 'precision', 'recall', 'f1'], \n",
    "                          cv_num=cross_val_num, show_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dimensionality reduction using PCA\n",
    "# example https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_x = pca.fit(smote_x).transform(smote_x)\n",
    "print('pca_x:',pca_x.shape)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s' % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['red', 'blue']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [1, 2], ['AD-MCI','NC']):\n",
    "    plt.scatter(pca_x[smote_y == i, 0], pca_x[smote_y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "    \n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of data set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split of pca_x and smote_y to train test data set\n",
    "pca_train_x, pca_test_x, pca_train_y, pca_test_y = train_test_split(pca_x, smote_y, random_state=7, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train and evaluate models using the 2 components from PCA\n",
    "trained_models_using_pca_comp = train.train_models(pca_train_x, smote_train_y, smote_test_x, smote_test_y)\n",
    "evaluate.generate_metrics(trained_models_using_pca_comp, pca_test_x, pca_test_y, \n",
    "                          ['accuracy', 'precision', 'recall', 'f1'], cv_num=cross_val_num, show_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dimensionality reduction using LDA\n",
    "\n",
    "# creating two components separately due to the know restriction n_components cannot be larger than min(n_features, n_classes - 1)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=1)\n",
    "\n",
    "# print(smote_x.iloc[:, [0,1,2,3]])\n",
    "# education  avg_gr_time_in_gs  family_med_history  total_gr_in_gs\n",
    "# Selecting (avg_gr_time_in_gs, family_med_history) and (education, total_gr_in_gs) based on Spearman correlation coefficient\n",
    "\n",
    "# print('lda_x_one from:',smote_x.iloc[:, [0,3]].shape)\n",
    "lda_x_one = lda.fit_transform(smote_x.iloc[:, [0,3]], smote_y)\n",
    "# print('lda_x_one:', lda_x_one.shape)\n",
    "\n",
    "# print('lda_x_two from:',smote_x.iloc[:, [1,2]].shape)\n",
    "lda_x_two = lda.fit_transform(smote_x.iloc[:, [1,2]], smote_y)\n",
    "# print('lda_x_two:', lda_x_two.shape)\n",
    "\n",
    "lda_x = np.concatenate((lda_x_one, lda_x_two),axis=1)\n",
    "# print('lda_x:',lda_x.shape)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['red', 'blue']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [1, 2], ['AD-MCI','NC']):\n",
    "    plt.scatter(lda_x[smote_y == i, 0], lda_x[smote_y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)\n",
    "    \n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of data set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split of pca_x and smote_y to train test data set\n",
    "lda_train_x, lda_test_x, lda_train_y, lda_test_y = train_test_split(lda_x, smote_y, random_state=7, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate models using the 2 components from LDA\n",
    "trained_models_using_lda = train.train_models(lda_train_x, smote_train_y, smote_test_x, smote_test_y)\n",
    "evaluate.generate_metrics(trained_models_using_lda, lda_test_x, lda_test_y, \n",
    "                          ['accuracy', 'precision', 'recall', 'f1'], cv_num=cross_val_num, show_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "shortcuts": {
    "edit-all-cells": "ctrl-e",
    "reveal_shortcuts": {
     "chalkboard": {
      "clear": "ctrl-k",
      "toggleNotesCanvas": "]"
     },
     "main": {
      "toggleOverview": "tab"
     }
    },
    "scroll": true,
    "slideshow": "alt-a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
